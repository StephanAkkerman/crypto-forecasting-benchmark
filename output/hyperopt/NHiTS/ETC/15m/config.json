[{"num_stacks": 3, "num_blocks": 3, "num_layers": 2, "layer_widths": 512, "input_chunk_length": 1, "n_epochs": 50, "batch_size": 64, "dropout": 0.25576967000961304, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}, {"num_stacks": 3, "num_blocks": 5, "num_layers": 4, "layer_widths": 1024, "input_chunk_length": 12, "n_epochs": 75, "batch_size": 16, "dropout": 0.20413517951965332, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}, {"num_stacks": 3, "num_blocks": 10, "num_layers": 4, "layer_widths": 1024, "input_chunk_length": 12, "n_epochs": 50, "batch_size": 128, "dropout": 0.15589815378189087, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}, {"num_stacks": 2, "num_blocks": 2, "num_layers": 3, "layer_widths": 512, "input_chunk_length": 9, "n_epochs": 100, "batch_size": 128, "dropout": 0.16697055101394653, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}, {"num_stacks": 3, "num_blocks": 3, "num_layers": 2, "layer_widths": 256, "input_chunk_length": 12, "n_epochs": 50, "batch_size": 128, "dropout": 0.13074763119220734, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}, {"num_stacks": 3, "num_blocks": 5, "num_layers": 2, "layer_widths": 256, "input_chunk_length": 9, "n_epochs": 75, "batch_size": 16, "dropout": 0.05258946865797043, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}, {"num_stacks": 2, "num_blocks": 2, "num_layers": 3, "layer_widths": 512, "input_chunk_length": 9, "n_epochs": 100, "batch_size": 128, "dropout": 0.2141574828434261, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}, {"num_stacks": 2, "num_blocks": 5, "num_layers": 4, "layer_widths": 512, "input_chunk_length": 9, "n_epochs": 100, "batch_size": 128, "dropout": 0.1908747391358196, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}, {"num_stacks": 2, "num_blocks": 2, "num_layers": 3, "layer_widths": 512, "input_chunk_length": 9, "n_epochs": 100, "batch_size": 128, "dropout": 0.2785260622817255, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}]