[{"num_stacks": 2, "num_blocks": 2, "num_layers": 4, "layer_widths": 512, "input_chunk_length": 12, "n_epochs": 75, "batch_size": 64, "dropout": 0.020197400823235512, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}, {"num_stacks": 3, "num_blocks": 5, "num_layers": 1, "layer_widths": 256, "input_chunk_length": 12, "n_epochs": 50, "batch_size": 16, "dropout": 0.2030595988035202, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}, {"num_stacks": 3, "num_blocks": 10, "num_layers": 1, "layer_widths": 256, "input_chunk_length": 9, "n_epochs": 75, "batch_size": 64, "dropout": 0.1919042468070984, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}, {"num_stacks": 3, "num_blocks": 1, "num_layers": 2, "layer_widths": 512, "input_chunk_length": 6, "n_epochs": 25, "batch_size": 32, "dropout": 0.4237857162952423, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}, {"num_stacks": 2, "num_blocks": 10, "num_layers": 3, "layer_widths": 256, "input_chunk_length": 3, "n_epochs": 100, "batch_size": 32, "dropout": 0.3653010427951813, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}, {"num_stacks": 3, "num_blocks": 5, "num_layers": 3, "layer_widths": 512, "input_chunk_length": 9, "n_epochs": 25, "batch_size": 16, "dropout": 0.059905603528022766, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}, {"num_stacks": 2, "num_blocks": 1, "num_layers": 4, "layer_widths": 1024, "input_chunk_length": 12, "n_epochs": 100, "batch_size": 128, "dropout": 0.037773555558723186, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}, {"num_stacks": 4, "num_blocks": 1, "num_layers": 4, "layer_widths": 512, "input_chunk_length": 12, "n_epochs": 25, "batch_size": 64, "dropout": 0.022376981483953923, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}, {"num_stacks": 4, "num_blocks": 3, "num_layers": 4, "layer_widths": 512, "input_chunk_length": 12, "n_epochs": 75, "batch_size": 128, "dropout": 0.01077125240917333, "pl_trainer_kwargs": {"enable_progress_bar": false, "accelerator": "auto"}, "output_chunk_length": 1}]